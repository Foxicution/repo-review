{"ast":null,"code":"import _asyncToGenerator from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _get from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/get\";\nimport _getPrototypeOf from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _slicedToArray from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _createForOfIteratorHelper from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper\";\nimport _classCallCheck from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _inherits from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/home/fox/Projects/Python/repo-review/streamlit_components/graph_visualizer/frontend/node_modules/@babel/runtime/helpers/esm/createSuper\";\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = \"function\" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || \"@@iterator\", asyncIteratorSymbol = $Symbol.asyncIterator || \"@@asyncIterator\", toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, \"\"); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, \"_invoke\", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: \"normal\", arg: fn.call(obj, arg) }; } catch (err) { return { type: \"throw\", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { [\"next\", \"throw\", \"return\"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if (\"throw\" !== record.type) { var result = record.arg, value = result.value; return value && \"object\" == typeof value && hasOwn.call(value, \"__await\") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke(\"next\", value, resolve, reject); }, function (err) { invoke(\"throw\", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke(\"throw\", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, \"_invoke\", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = \"suspendedStart\"; return function (method, arg) { if (\"executing\" === state) throw new Error(\"Generator is already running\"); if (\"completed\" === state) { if (\"throw\" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if (\"next\" === context.method) context.sent = context._sent = context.arg;else if (\"throw\" === context.method) { if (\"suspendedStart\" === state) throw state = \"completed\", context.arg; context.dispatchException(context.arg); } else \"return\" === context.method && context.abrupt(\"return\", context.arg); state = \"executing\"; var record = tryCatch(innerFn, self, context); if (\"normal\" === record.type) { if (state = context.done ? \"completed\" : \"suspendedYield\", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } \"throw\" === record.type && (state = \"completed\", context.method = \"throw\", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var method = delegate.iterator[context.method]; if (undefined === method) { if (context.delegate = null, \"throw\" === context.method) { if (delegate.iterator.return && (context.method = \"return\", context.arg = undefined, maybeInvokeDelegate(delegate, context), \"throw\" === context.method)) return ContinueSentinel; context.method = \"throw\", context.arg = new TypeError(\"The iterator does not provide a 'throw' method\"); } return ContinueSentinel; } var record = tryCatch(method, delegate.iterator, context.arg); if (\"throw\" === record.type) return context.method = \"throw\", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, \"return\" !== context.method && (context.method = \"next\", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = \"throw\", context.arg = new TypeError(\"iterator result is not an object\"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = \"normal\", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: \"root\" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if (\"function\" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) { if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; } return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, \"constructor\", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, \"constructor\", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, \"GeneratorFunction\"), exports.isGeneratorFunction = function (genFun) { var ctor = \"function\" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || \"GeneratorFunction\" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, \"GeneratorFunction\")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, \"Generator\"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, \"toString\", function () { return \"[object Generator]\"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) { keys.push(key); } return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) { \"t\" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); } }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if (\"throw\" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = \"throw\", record.arg = exception, context.next = loc, caught && (context.method = \"next\", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if (\"root\" === entry.tryLoc) return handle(\"end\"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, \"catchLoc\"), hasFinally = hasOwn.call(entry, \"finallyLoc\"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error(\"try statement without catch or finally\"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, \"finallyLoc\") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && (\"break\" === type || \"continue\" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = \"next\", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if (\"throw\" === record.type) throw record.arg; return \"break\" === record.type || \"continue\" === record.type ? this.next = record.arg : \"return\" === record.type ? (this.rval = this.arg = record.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, catch: function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if (\"throw\" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, \"next\" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }\nfunction _asyncIterator(iterable) { var method, async, sync, retry = 2; for (\"undefined\" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;) { if (async && null != (method = iterable[async])) return method.call(iterable); if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator(method.call(iterable)); async = \"@@asyncIterator\", sync = \"@@iterator\"; } throw new TypeError(\"Object is not async iterable\"); }\nfunction AsyncFromSyncIterator(s) { function AsyncFromSyncIteratorContinuation(r) { if (Object(r) !== r) return Promise.reject(new TypeError(r + \" is not an object.\")); var done = r.done; return Promise.resolve(r.value).then(function (value) { return { value: value, done: done }; }); } return AsyncFromSyncIterator = function AsyncFromSyncIterator(s) { this.s = s, this.n = s.next; }, AsyncFromSyncIterator.prototype = { s: null, n: null, next: function next() { return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments)); }, return: function _return(value) { var ret = this.s.return; return void 0 === ret ? Promise.resolve({ value: value, done: !0 }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments)); }, throw: function _throw(value) { var thr = this.s.return; return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments)); } }, new AsyncFromSyncIterator(s); }\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { ReadableInterop } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\nexport var RecordBatchWriter = /*#__PURE__*/function (_ReadableInterop, _Symbol$asyncIterator) {\n  _inherits(RecordBatchWriter, _ReadableInterop);\n  var _super = _createSuper(RecordBatchWriter);\n  function RecordBatchWriter(options) {\n    var _this;\n    _classCallCheck(this, RecordBatchWriter);\n    _this = _super.call(this);\n    _this._position = 0;\n    _this._started = false;\n    // @ts-ignore\n    _this._sink = new AsyncByteQueue();\n    _this._schema = null;\n    _this._dictionaryBlocks = [];\n    _this._recordBatchBlocks = [];\n    _this._dictionaryDeltaOffsets = new Map();\n    isObject(options) || (options = {\n      autoDestroy: true,\n      writeLegacyIpcFormat: false\n    });\n    _this._autoDestroy = typeof options.autoDestroy === 'boolean' ? options.autoDestroy : true;\n    _this._writeLegacyIpcFormat = typeof options.writeLegacyIpcFormat === 'boolean' ? options.writeLegacyIpcFormat : false;\n    return _this;\n  }\n  /** @nocollapse */\n  // @ts-ignore\n  _createClass(RecordBatchWriter, [{\n    key: \"toString\",\n    value: function toString() {\n      var sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      return this._sink.toString(sync);\n    }\n  }, {\n    key: \"toUint8Array\",\n    value: function toUint8Array() {\n      var sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      return this._sink.toUint8Array(sync);\n    }\n  }, {\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      var _this2 = this;\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return _this2.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(this, input);\n      }\n      return _writeAll(this, input);\n    }\n  }, {\n    key: \"closed\",\n    get: function get() {\n      return this._sink.closed;\n    }\n  }, {\n    key: _Symbol$asyncIterator,\n    value: function value() {\n      return this._sink[Symbol.asyncIterator]();\n    }\n  }, {\n    key: \"toDOMStream\",\n    value: function toDOMStream(options) {\n      return this._sink.toDOMStream(options);\n    }\n  }, {\n    key: \"toNodeStream\",\n    value: function toNodeStream(options) {\n      return this._sink.toNodeStream(options);\n    }\n  }, {\n    key: \"close\",\n    value: function close() {\n      return this.reset()._sink.close();\n    }\n  }, {\n    key: \"abort\",\n    value: function abort(reason) {\n      return this.reset()._sink.abort(reason);\n    }\n  }, {\n    key: \"finish\",\n    value: function finish() {\n      this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n      return this;\n    }\n  }, {\n    key: \"reset\",\n    value: function reset() {\n      var sink = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._sink;\n      var schema = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n      if (sink === this._sink || sink instanceof AsyncByteQueue) {\n        this._sink = sink;\n      } else {\n        this._sink = new AsyncByteQueue();\n        if (sink && isWritableDOMStream(sink)) {\n          this.toDOMStream({\n            type: 'bytes'\n          }).pipeTo(sink);\n        } else if (sink && isWritableNodeStream(sink)) {\n          this.toNodeStream({\n            objectMode: false\n          }).pipe(sink);\n        }\n      }\n      if (this._started && this._schema) {\n        this._writeFooter(this._schema);\n      }\n      this._started = false;\n      this._dictionaryBlocks = [];\n      this._recordBatchBlocks = [];\n      this._dictionaryDeltaOffsets = new Map();\n      if (!schema || !schema.compareTo(this._schema)) {\n        if (schema === null) {\n          this._position = 0;\n          this._schema = null;\n        } else {\n          this._started = true;\n          this._schema = schema;\n          this._writeSchema(schema);\n        }\n      }\n      return this;\n    }\n  }, {\n    key: \"write\",\n    value: function write(payload) {\n      var schema = null;\n      if (!this._sink) {\n        throw new Error(\"RecordBatchWriter is closed\");\n      } else if (payload === null || payload === undefined) {\n        return this.finish() && undefined;\n      } else if (payload instanceof Table && !(schema = payload.schema)) {\n        return this.finish() && undefined;\n      } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n        return this.finish() && undefined;\n      }\n      if (schema && !schema.compareTo(this._schema)) {\n        if (this._started && this._autoDestroy) {\n          return this.close();\n        }\n        this.reset(this._sink, schema);\n      }\n      if (payload instanceof RecordBatch) {\n        if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n          this._writeRecordBatch(payload);\n        }\n      } else if (payload instanceof Table) {\n        this.writeAll(payload.chunks);\n      } else if (isIterable(payload)) {\n        this.writeAll(payload);\n      }\n    }\n  }, {\n    key: \"_writeMessage\",\n    value: function _writeMessage(message) {\n      var alignment = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 8;\n      var a = alignment - 1;\n      var buffer = Message.encode(message);\n      var flatbufferSize = buffer.byteLength;\n      var prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n      var alignedSize = flatbufferSize + prefixSize + a & ~a;\n      var nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n      if (message.headerType === MessageHeader.RecordBatch) {\n        this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n      } else if (message.headerType === MessageHeader.DictionaryBatch) {\n        this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n      }\n      // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n      if (!this._writeLegacyIpcFormat) {\n        this._write(Int32Array.of(-1));\n      }\n      // Write the flatbuffer size prefix including padding\n      this._write(Int32Array.of(alignedSize - prefixSize));\n      // Write the flatbuffer\n      if (flatbufferSize > 0) {\n        this._write(buffer);\n      }\n      // Write any padding\n      return this._writePadding(nPaddingBytes);\n    }\n  }, {\n    key: \"_write\",\n    value: function _write(chunk) {\n      if (this._started) {\n        var buffer = toUint8Array(chunk);\n        if (buffer && buffer.byteLength > 0) {\n          this._sink.write(buffer);\n          this._position += buffer.byteLength;\n        }\n      }\n      return this;\n    }\n  }, {\n    key: \"_writeSchema\",\n    value: function _writeSchema(schema) {\n      return this._writeMessage(Message.from(schema));\n    }\n    // @ts-ignore\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      // eos bytes\n      return this._writeLegacyIpcFormat ? this._write(Int32Array.of(0)) : this._write(Int32Array.of(-1, 0));\n    }\n  }, {\n    key: \"_writeMagic\",\n    value: function _writeMagic() {\n      return this._write(MAGIC);\n    }\n  }, {\n    key: \"_writePadding\",\n    value: function _writePadding(nBytes) {\n      return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n  }, {\n    key: \"_writeRecordBatch\",\n    value: function _writeRecordBatch(batch) {\n      var _VectorAssembler$asse = VectorAssembler.assemble(batch),\n        byteLength = _VectorAssembler$asse.byteLength,\n        nodes = _VectorAssembler$asse.nodes,\n        bufferRegions = _VectorAssembler$asse.bufferRegions,\n        buffers = _VectorAssembler$asse.buffers;\n      var recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n      var message = Message.from(recordBatch, byteLength);\n      return this._writeDictionaries(batch)._writeMessage(message)._writeBodyBuffers(buffers);\n    }\n  }, {\n    key: \"_writeDictionaryBatch\",\n    value: function _writeDictionaryBatch(dictionary, id) {\n      var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n      this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n      var _VectorAssembler$asse2 = VectorAssembler.assemble(dictionary),\n        byteLength = _VectorAssembler$asse2.byteLength,\n        nodes = _VectorAssembler$asse2.nodes,\n        bufferRegions = _VectorAssembler$asse2.bufferRegions,\n        buffers = _VectorAssembler$asse2.buffers;\n      var recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n      var dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n      var message = Message.from(dictionaryBatch, byteLength);\n      return this._writeMessage(message)._writeBodyBuffers(buffers);\n    }\n  }, {\n    key: \"_writeBodyBuffers\",\n    value: function _writeBodyBuffers(buffers) {\n      var buffer;\n      var size, padding;\n      for (var i = -1, n = buffers.length; ++i < n;) {\n        if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n          this._write(buffer);\n          if ((padding = (size + 7 & ~7) - size) > 0) {\n            this._writePadding(padding);\n          }\n        }\n      }\n      return this;\n    }\n  }, {\n    key: \"_writeDictionaries\",\n    value: function _writeDictionaries(batch) {\n      var _iterator2 = _createForOfIteratorHelper(batch.dictionaries),\n        _step2;\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var _step2$value = _slicedToArray(_step2.value, 2),\n            id = _step2$value[0],\n            dictionary = _step2$value[1];\n          var offset = this._dictionaryDeltaOffsets.get(id) || 0;\n          if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n            var chunks = 'chunks' in dictionary ? dictionary.chunks : [dictionary];\n            var _iterator3 = _createForOfIteratorHelper(chunks),\n              _step3;\n            try {\n              for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                var chunk = _step3.value;\n                this._writeDictionaryBatch(chunk, id, offset > 0);\n                offset += chunk.length;\n              }\n            } catch (err) {\n              _iterator3.e(err);\n            } finally {\n              _iterator3.f();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n      return this;\n    }\n  }], [{\n    key: \"throughNode\",\n    value: function throughNode(options) {\n      throw new Error(\"\\\"throughNode\\\" not available in this environment\");\n    }\n    /** @nocollapse */\n  }, {\n    key: \"throughDOM\",\n    value: function throughDOM(\n    // @ts-ignore\n    writableStrategy,\n    // @ts-ignore\n    readableStrategy) {\n      throw new Error(\"\\\"throughDOM\\\" not available in this environment\");\n    }\n  }]);\n  return RecordBatchWriter;\n}(ReadableInterop, Symbol.asyncIterator);\n/** @ignore */\nexport var RecordBatchStreamWriter = /*#__PURE__*/function (_RecordBatchWriter) {\n  _inherits(RecordBatchStreamWriter, _RecordBatchWriter);\n  var _super2 = _createSuper(RecordBatchStreamWriter);\n  function RecordBatchStreamWriter() {\n    _classCallCheck(this, RecordBatchStreamWriter);\n    return _super2.apply(this, arguments);\n  }\n  _createClass(RecordBatchStreamWriter, null, [{\n    key: \"writeAll\",\n    value: /** @nocollapse */\n    function writeAll(input, options) {\n      var writer = new RecordBatchStreamWriter(options);\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return writer.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(writer, input);\n      }\n      return _writeAll(writer, input);\n    }\n  }]);\n  return RecordBatchStreamWriter;\n}(RecordBatchWriter);\n/** @ignore */\nexport var RecordBatchFileWriter = /*#__PURE__*/function (_RecordBatchWriter2) {\n  _inherits(RecordBatchFileWriter, _RecordBatchWriter2);\n  var _super3 = _createSuper(RecordBatchFileWriter);\n  function RecordBatchFileWriter() {\n    var _this3;\n    _classCallCheck(this, RecordBatchFileWriter);\n    _this3 = _super3.call(this);\n    _this3._autoDestroy = true;\n    return _this3;\n  }\n  /** @nocollapse */\n  _createClass(RecordBatchFileWriter, [{\n    key: \"_writeSchema\",\n    value:\n    // @ts-ignore\n    function _writeSchema(schema) {\n      return this._writeMagic()._writePadding(2);\n    }\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      var buffer = Footer.encode(new Footer(schema, MetadataVersion.V4, this._recordBatchBlocks, this._dictionaryBlocks));\n      return _get(_getPrototypeOf(RecordBatchFileWriter.prototype), \"_writeFooter\", this).call(this, schema) // EOS bytes for sequential readers\n      ._write(buffer) // Write the flatbuffer\n      ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n      ._writeMagic(); // then the magic suffix\n    }\n  }], [{\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      var writer = new RecordBatchFileWriter();\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return writer.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(writer, input);\n      }\n      return _writeAll(writer, input);\n    }\n  }]);\n  return RecordBatchFileWriter;\n}(RecordBatchWriter);\n/** @ignore */\nexport var RecordBatchJSONWriter = /*#__PURE__*/function (_RecordBatchWriter3) {\n  _inherits(RecordBatchJSONWriter, _RecordBatchWriter3);\n  var _super4 = _createSuper(RecordBatchJSONWriter);\n  function RecordBatchJSONWriter() {\n    var _this4;\n    _classCallCheck(this, RecordBatchJSONWriter);\n    _this4 = _super4.call(this);\n    _this4._autoDestroy = true;\n    _this4._recordBatches = [];\n    _this4._dictionaries = [];\n    return _this4;\n  }\n  /** @nocollapse */\n  _createClass(RecordBatchJSONWriter, [{\n    key: \"_writeMessage\",\n    value: function _writeMessage() {\n      return this;\n    }\n    // @ts-ignore\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      return this;\n    }\n  }, {\n    key: \"_writeSchema\",\n    value: function _writeSchema(schema) {\n      return this._write(\"{\\n  \\\"schema\\\": \".concat(JSON.stringify({\n        fields: schema.fields.map(fieldToJSON)\n      }, null, 2)));\n    }\n  }, {\n    key: \"_writeDictionaries\",\n    value: function _writeDictionaries(batch) {\n      if (batch.dictionaries.size > 0) {\n        this._dictionaries.push(batch);\n      }\n      return this;\n    }\n  }, {\n    key: \"_writeDictionaryBatch\",\n    value: function _writeDictionaryBatch(dictionary, id) {\n      var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n      this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n      this._write(this._dictionaryBlocks.length === 0 ? \"    \" : \",\\n    \");\n      this._write(\"\".concat(dictionaryBatchToJSON(dictionary, id, isDelta)));\n      this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n      return this;\n    }\n  }, {\n    key: \"_writeRecordBatch\",\n    value: function _writeRecordBatch(batch) {\n      this._writeDictionaries(batch);\n      this._recordBatches.push(batch);\n      return this;\n    }\n  }, {\n    key: \"close\",\n    value: function close() {\n      if (this._dictionaries.length > 0) {\n        this._write(\",\\n  \\\"dictionaries\\\": [\\n\");\n        var _iterator4 = _createForOfIteratorHelper(this._dictionaries),\n          _step4;\n        try {\n          for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n            var batch = _step4.value;\n            _get(_getPrototypeOf(RecordBatchJSONWriter.prototype), \"_writeDictionaries\", this).call(this, batch);\n          }\n        } catch (err) {\n          _iterator4.e(err);\n        } finally {\n          _iterator4.f();\n        }\n        this._write(\"\\n  ]\");\n      }\n      if (this._recordBatches.length > 0) {\n        for (var i = -1, n = this._recordBatches.length; ++i < n;) {\n          this._write(i === 0 ? \",\\n  \\\"batches\\\": [\\n    \" : \",\\n    \");\n          this._write(\"\".concat(recordBatchToJSON(this._recordBatches[i])));\n          this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n        }\n        this._write(\"\\n  ]\");\n      }\n      if (this._schema) {\n        this._write(\"\\n}\");\n      }\n      this._dictionaries = [];\n      this._recordBatches = [];\n      return _get(_getPrototypeOf(RecordBatchJSONWriter.prototype), \"close\", this).call(this);\n    }\n  }], [{\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      return new RecordBatchJSONWriter().writeAll(input);\n    }\n  }]);\n  return RecordBatchJSONWriter;\n}(RecordBatchWriter);\n/** @ignore */\nfunction _writeAll(writer, input) {\n  var chunks = input;\n  if (input instanceof Table) {\n    chunks = input.chunks;\n    writer.reset(undefined, input.schema);\n  }\n  var _iterator5 = _createForOfIteratorHelper(chunks),\n    _step5;\n  try {\n    for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n      var batch = _step5.value;\n      writer.write(batch);\n    }\n  } catch (err) {\n    _iterator5.e(err);\n  } finally {\n    _iterator5.f();\n  }\n  return writer.finish();\n}\n/** @ignore */\nfunction writeAllAsync(_x, _x2) {\n  return _writeAllAsync.apply(this, arguments);\n}\n/** @ignore */\nfunction _writeAllAsync() {\n  _writeAllAsync = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(writer, batches) {\n    var _iteratorAbruptCompletion, _didIteratorError, _iteratorError, _iterator, _step, batch;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _iteratorAbruptCompletion = false;\n            _didIteratorError = false;\n            _context.prev = 2;\n            _iterator = _asyncIterator(batches);\n          case 4:\n            _context.next = 6;\n            return _iterator.next();\n          case 6:\n            if (!(_iteratorAbruptCompletion = !(_step = _context.sent).done)) {\n              _context.next = 12;\n              break;\n            }\n            batch = _step.value;\n            writer.write(batch);\n          case 9:\n            _iteratorAbruptCompletion = false;\n            _context.next = 4;\n            break;\n          case 12:\n            _context.next = 18;\n            break;\n          case 14:\n            _context.prev = 14;\n            _context.t0 = _context[\"catch\"](2);\n            _didIteratorError = true;\n            _iteratorError = _context.t0;\n          case 18:\n            _context.prev = 18;\n            _context.prev = 19;\n            if (!(_iteratorAbruptCompletion && _iterator.return != null)) {\n              _context.next = 23;\n              break;\n            }\n            _context.next = 23;\n            return _iterator.return();\n          case 23:\n            _context.prev = 23;\n            if (!_didIteratorError) {\n              _context.next = 26;\n              break;\n            }\n            throw _iteratorError;\n          case 26:\n            return _context.finish(23);\n          case 27:\n            return _context.finish(18);\n          case 28:\n            return _context.abrupt(\"return\", writer.finish());\n          case 29:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, null, [[2, 14, 18, 28], [19,, 23, 27]]);\n  }));\n  return _writeAllAsync.apply(this, arguments);\n}\nfunction fieldToJSON(_ref) {\n  var name = _ref.name,\n    type = _ref.type,\n    nullable = _ref.nullable;\n  var assembler = new JSONTypeAssembler();\n  return {\n    'name': name,\n    'nullable': nullable,\n    'type': assembler.visit(type),\n    'children': (type.children || []).map(fieldToJSON),\n    'dictionary': !DataType.isDictionary(type) ? undefined : {\n      'id': type.id,\n      'isOrdered': type.isOrdered,\n      'indexType': assembler.visit(type.indices)\n    }\n  };\n}\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary, id) {\n  var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  var field = new Field(\"\".concat(id), dictionary.type, dictionary.nullCount > 0);\n  var columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n  return JSON.stringify({\n    'id': id,\n    'isDelta': isDelta,\n    'data': {\n      'count': dictionary.length,\n      'columns': columns\n    }\n  }, null, 2);\n}\n/** @ignore */\nfunction recordBatchToJSON(records) {\n  return JSON.stringify({\n    'count': records.length,\n    'columns': JSONVectorAssembler.assemble(records)\n  }, null, 2);\n}","map":{"version":3,"mappings":";;;;;;;;;+CACA;AAAA;AAAA;AADA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,KAAK,QAAQ,UAAU;AAChC,SAASC,KAAK,QAAQ,WAAW;AAEjC,SAASC,MAAM,QAAQ,WAAW;AAClC,SAASC,QAAQ,QAAQ,SAAS;AAClC,SAAiBC,KAAK,QAAQ,WAAW;AACzC,SAASC,OAAO,QAAQ,oBAAoB;AAC5C,OAAO,KAAKC,QAAQ,MAAM,oBAAoB;AAC9C,SAASC,SAAS,EAAEC,MAAM,QAAQ,iBAAiB;AACnD,SAASC,aAAa,EAAEC,eAAe,QAAQ,SAAS;AACxD,SAAuBC,cAAc,QAAQ,cAAc;AAC3D,SAASC,eAAe,QAAQ,4BAA4B;AAC5D,SAASC,iBAAiB,QAAQ,8BAA8B;AAChE,SAASC,mBAAmB,QAAQ,gCAAgC;AACpE,SAA+BC,YAAY,QAAQ,gBAAgB;AACnE,SAASC,WAAW,EAAEC,oCAAoC,QAAQ,gBAAgB;AAClF,SAAmBC,eAAe,QAAkC,kBAAkB;AACtF,SAASC,SAAS,EAAEC,eAAe,EAAEC,mBAAmB,EAAEC,oBAAoB,EAAEC,UAAU,EAAEC,QAAQ,QAAQ,gBAAgB;AAgB5H,WAAaC,iBAA+D;EAAA;EAAA;EAiBxE,2BAAYC,OAAwC;IAAA;IAAA;IAChD;IAMM,eAAS,GAAG,CAAC;IACb,cAAQ,GAAG,KAAK;IAG1B;IACU,WAAK,GAAG,IAAIf,cAAc,EAAE;IAC5B,aAAO,GAAkB,IAAI;IAC7B,uBAAiB,GAAgB,EAAE;IACnC,wBAAkB,GAAgB,EAAE;IACpC,6BAAuB,GAAG,IAAIgB,GAAG,EAAkB;IAdzDH,QAAQ,CAACE,OAAO,CAAC,KAAKA,OAAO,GAAG;MAAEE,WAAW,EAAE,IAAI;MAAEC,oBAAoB,EAAE;IAAK,CAAE,CAAC;IACnF,MAAKC,YAAY,GAAI,OAAOJ,OAAO,CAACE,WAAW,KAAK,SAAS,GAAIF,OAAO,CAACE,WAAW,GAAG,IAAI;IAC3F,MAAKG,qBAAqB,GAAI,OAAOL,OAAO,CAACG,oBAAoB,KAAK,SAAS,GAAIH,OAAO,CAACG,oBAAoB,GAAG,KAAK;IAAC;EAC5H;EApBA;EACA;EAAA;IAAA;IAAA,OAkCO,oBAA0B;MAAA,IAAjBG,2EAAY,KAAK;MAC7B,OAAO,IAAI,CAACC,KAAK,CAACC,QAAQ,CAACF,IAAI,CAA6B;IAChE;EAAC;IAAA;IAAA,OAGM,wBAA8B;MAAA,IAAjBA,2EAAY,KAAK;MACjC,OAAO,IAAI,CAACC,KAAK,CAAClB,YAAY,CAACiB,IAAI,CAAqC;IAC5E;EAAC;IAAA;IAAA,OAMM,kBAASG,KAA6F;MAAA;MACzG,IAAIhB,SAAS,CAAMgB,KAAK,CAAC,EAAE;QACvB,OAAOA,KAAK,CAACC,IAAI,CAAC,UAACC,CAAC;UAAA,OAAK,MAAI,CAACC,QAAQ,CAACD,CAAC,CAAC;QAAA,EAAC;OAC7C,MAAM,IAAIjB,eAAe,CAAiBe,KAAK,CAAC,EAAE;QAC/C,OAAOI,aAAa,CAAC,IAAI,EAAEJ,KAAK,CAAC;;MAErC,OAAOG,SAAQ,CAAC,IAAI,EAAQH,KAAK,CAAC;IACtC;EAAC;IAAA;IAAA,KAED,eAAiB;MAAK,OAAO,IAAI,CAACF,KAAK,CAACO,MAAM;IAAE;EAAC;IAAA;IAAA,OAC1C,iBAAsB;MAAK,OAAO,IAAI,CAACP,KAAK,CAACQ,MAAM,CAACC,aAAa,CAAC,EAAE;IAAE;EAAC;IAAA;IAAA,OACvE,qBAAYhB,OAAkC;MAAI,OAAO,IAAI,CAACO,KAAK,CAACU,WAAW,CAACjB,OAAO,CAAC;IAAE;EAAC;IAAA;IAAA,OAC3F,sBAAaA,OAA0C;MAAI,OAAO,IAAI,CAACO,KAAK,CAACW,YAAY,CAAClB,OAAO,CAAC;IAAE;EAAC;IAAA;IAAA,OAErG,iBAAK;MACR,OAAO,IAAI,CAACmB,KAAK,EAAE,CAACZ,KAAK,CAACa,KAAK,EAAE;IACrC;EAAC;IAAA;IAAA,OACM,eAAMC,MAAY;MACrB,OAAO,IAAI,CAACF,KAAK,EAAE,CAACZ,KAAK,CAACe,KAAK,CAACD,MAAM,CAAC;IAC3C;EAAC;IAAA;IAAA,OACM,kBAAM;MACT,IAAI,CAACjB,YAAY,GAAG,IAAI,CAACgB,KAAK,EAAE,GAAG,IAAI,CAACD,KAAK,CAAC,IAAI,CAACZ,KAAK,EAAE,IAAI,CAACgB,OAAO,CAAC;MACvE,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OACM,iBAA4F;MAAA,IAAtFC,2EAA2C,IAAI,CAACjB,KAAK;MAAA,IAAEkB,6EAA2B,IAAI;MAE/F,IAAKD,IAAI,KAAK,IAAI,CAACjB,KAAK,IAAMiB,IAAI,YAAYvC,cAAe,EAAE;QAC3D,IAAI,CAACsB,KAAK,GAAGiB,IAAsB;OACtC,MAAM;QACH,IAAI,CAACjB,KAAK,GAAG,IAAItB,cAAc,EAAE;QACjC,IAAIuC,IAAI,IAAI7B,mBAAmB,CAAC6B,IAAI,CAAC,EAAE;UACnC,IAAI,CAACP,WAAW,CAAC;YAAES,IAAI,EAAE;UAAO,CAAE,CAAC,CAACC,MAAM,CAACH,IAAI,CAAC;SACnD,MAAM,IAAIA,IAAI,IAAI5B,oBAAoB,CAAC4B,IAAI,CAAC,EAAE;UAC3C,IAAI,CAACN,YAAY,CAAC;YAAEU,UAAU,EAAE;UAAK,CAAE,CAAC,CAACC,IAAI,CAACL,IAAI,CAAC;;;MAI3D,IAAI,IAAI,CAACM,QAAQ,IAAI,IAAI,CAACP,OAAO,EAAE;QAC/B,IAAI,CAACQ,YAAY,CAAC,IAAI,CAACR,OAAO,CAAC;;MAGnC,IAAI,CAACO,QAAQ,GAAG,KAAK;MACrB,IAAI,CAACE,iBAAiB,GAAG,EAAE;MAC3B,IAAI,CAACC,kBAAkB,GAAG,EAAE;MAC5B,IAAI,CAACC,uBAAuB,GAAG,IAAIjC,GAAG,EAAE;MAExC,IAAI,CAACwB,MAAM,IAAI,CAAEA,MAAM,CAACU,SAAS,CAAC,IAAI,CAACZ,OAAO,CAAE,EAAE;QAC9C,IAAIE,MAAM,KAAK,IAAI,EAAE;UACjB,IAAI,CAACW,SAAS,GAAG,CAAC;UAClB,IAAI,CAACb,OAAO,GAAG,IAAI;SACtB,MAAM;UACH,IAAI,CAACO,QAAQ,GAAG,IAAI;UACpB,IAAI,CAACP,OAAO,GAAGE,MAAM;UACrB,IAAI,CAACY,YAAY,CAACZ,MAAM,CAAC;;;MAIjC,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OAEM,eAAMa,OAAqE;MAE9E,IAAIb,MAAM,GAAqB,IAAI;MAEnC,IAAI,CAAC,IAAI,CAAClB,KAAK,EAAE;QACb,MAAM,IAAIgC,KAAK,+BAA+B;OACjD,MAAM,IAAID,OAAO,KAAK,IAAI,IAAIA,OAAO,KAAKE,SAAS,EAAE;QAClD,OAAO,IAAI,CAACC,MAAM,EAAE,IAAID,SAAS;OACpC,MAAM,IAAIF,OAAO,YAAYhE,KAAK,IAAI,EAAEmD,MAAM,GAAGa,OAAO,CAACb,MAAM,CAAC,EAAE;QAC/D,OAAO,IAAI,CAACgB,MAAM,EAAE,IAAID,SAAS;OACpC,MAAM,IAAIF,OAAO,YAAYhD,WAAW,IAAI,EAAEmC,MAAM,GAAGa,OAAO,CAACb,MAAM,CAAC,EAAE;QACrE,OAAO,IAAI,CAACgB,MAAM,EAAE,IAAID,SAAS;;MAGrC,IAAIf,MAAM,IAAI,CAACA,MAAM,CAACU,SAAS,CAAC,IAAI,CAACZ,OAAO,CAAC,EAAE;QAC3C,IAAI,IAAI,CAACO,QAAQ,IAAI,IAAI,CAAC1B,YAAY,EAAE;UACpC,OAAO,IAAI,CAACgB,KAAK,EAAE;;QAEvB,IAAI,CAACD,KAAK,CAAC,IAAI,CAACZ,KAAK,EAAEkB,MAAM,CAAC;;MAGlC,IAAIa,OAAO,YAAYhD,WAAW,EAAE;QAChC,IAAI,EAAEgD,OAAO,YAAY/C,oCAAoC,CAAC,EAAE;UAC5D,IAAI,CAACmD,iBAAiB,CAACJ,OAAO,CAAC;;OAEtC,MAAM,IAAIA,OAAO,YAAYhE,KAAK,EAAE;QACjC,IAAI,CAACsC,QAAQ,CAAC0B,OAAO,CAACK,MAAM,CAAC;OAChC,MAAM,IAAI9C,UAAU,CAACyC,OAAO,CAAC,EAAE;QAC5B,IAAI,CAAC1B,QAAQ,CAAC0B,OAAO,CAAC;;IAE9B;EAAC;IAAA;IAAA,OAES,uBAAuCM,OAAmB,EAAe;MAAA,IAAbC,SAAS,uEAAG,CAAC;MAE/E,IAAMC,CAAC,GAAGD,SAAS,GAAG,CAAC;MACvB,IAAME,MAAM,GAAGpE,OAAO,CAACqE,MAAM,CAACJ,OAAO,CAAC;MACtC,IAAMK,cAAc,GAAGF,MAAM,CAACG,UAAU;MACxC,IAAMC,UAAU,GAAG,CAAC,IAAI,CAAC9C,qBAAqB,GAAG,CAAC,GAAG,CAAC;MACtD,IAAM+C,WAAW,GAAIH,cAAc,GAAGE,UAAU,GAAGL,CAAC,GAAI,CAACA,CAAC;MAC1D,IAAMO,aAAa,GAAGD,WAAW,GAAGH,cAAc,GAAGE,UAAU;MAE/D,IAAIP,OAAO,CAACU,UAAU,KAAKvE,aAAa,CAACO,WAAW,EAAE;QAClD,IAAI,CAAC2C,kBAAkB,CAACsB,IAAI,CAAC,IAAI1E,SAAS,CAACuE,WAAW,EAAER,OAAO,CAACY,UAAU,EAAE,IAAI,CAACpB,SAAS,CAAC,CAAC;OAC/F,MAAM,IAAIQ,OAAO,CAACU,UAAU,KAAKvE,aAAa,CAAC0E,eAAe,EAAE;QAC7D,IAAI,CAACzB,iBAAiB,CAACuB,IAAI,CAAC,IAAI1E,SAAS,CAACuE,WAAW,EAAER,OAAO,CAACY,UAAU,EAAE,IAAI,CAACpB,SAAS,CAAC,CAAC;;MAG/F;MACA,IAAI,CAAC,IAAI,CAAC/B,qBAAqB,EAAE;QAC7B,IAAI,CAACqD,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;;MAElC;MACA,IAAI,CAACF,MAAM,CAACC,UAAU,CAACC,EAAE,CAACR,WAAW,GAAGD,UAAU,CAAC,CAAC;MACpD;MACA,IAAIF,cAAc,GAAG,CAAC,EAAE;QAAE,IAAI,CAACS,MAAM,CAACX,MAAM,CAAC;;MAC7C;MACA,OAAO,IAAI,CAACc,aAAa,CAACR,aAAa,CAAC;IAC5C;EAAC;IAAA;IAAA,OAES,gBAAOS,KAA2B;MACxC,IAAI,IAAI,CAAChC,QAAQ,EAAE;QACf,IAAMiB,MAAM,GAAG1D,YAAY,CAACyE,KAAK,CAAC;QAClC,IAAIf,MAAM,IAAIA,MAAM,CAACG,UAAU,GAAG,CAAC,EAAE;UACjC,IAAI,CAAC3C,KAAK,CAACwD,KAAK,CAAChB,MAAM,CAAC;UACxB,IAAI,CAACX,SAAS,IAAIW,MAAM,CAACG,UAAU;;;MAG3C,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OAES,sBAAazB,MAAiB;MACpC,OAAO,IAAI,CAACuC,aAAa,CAACrF,OAAO,CAACsF,IAAI,CAACxC,MAAM,CAAC,CAAC;IACnD;IAEA;EAAA;IAAA;IAAA,OACU,sBAAaA,MAAiB;MACpC;MACA,OAAO,IAAI,CAACpB,qBAAqB,GAC3B,IAAI,CAACqD,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,CAAC,GAC7B,IAAI,CAACF,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAC3C;EAAC;IAAA;IAAA,OAES,uBAAW;MACjB,OAAO,IAAI,CAACF,MAAM,CAACnF,KAAK,CAAC;IAC7B;EAAC;IAAA;IAAA,OAES,uBAAc2F,MAAc;MAClC,OAAOA,MAAM,GAAG,CAAC,GAAG,IAAI,CAACR,MAAM,CAAC,IAAIS,UAAU,CAACD,MAAM,CAAC,CAAC,GAAG,IAAI;IAClE;EAAC;IAAA;IAAA,OAES,2BAAkBE,KAAqB;MAC7C,4BAAsDlF,eAAe,CAACmF,QAAQ,CAACD,KAAK,CAAC;QAA7ElB,UAAU,yBAAVA,UAAU;QAAEoB,KAAK,yBAALA,KAAK;QAAEC,aAAa,yBAAbA,aAAa;QAAEC,OAAO,yBAAPA,OAAO;MACjD,IAAMC,WAAW,GAAG,IAAI7F,QAAQ,CAACU,WAAW,CAAC8E,KAAK,CAACM,MAAM,EAAEJ,KAAK,EAAEC,aAAa,CAAC;MAChF,IAAM3B,OAAO,GAAGjE,OAAO,CAACsF,IAAI,CAACQ,WAAW,EAAEvB,UAAU,CAAC;MACrD,OAAO,IAAI,CACNyB,kBAAkB,CAACP,KAAK,CAAC,CACzBJ,aAAa,CAACpB,OAAO,CAAC,CACtBgC,iBAAiB,CAACJ,OAAO,CAAC;IACnC;EAAC;IAAA;IAAA,OAES,+BAAsBK,UAAkB,EAAEC,EAAU,EAAiB;MAAA,IAAfC,OAAO,uEAAG,KAAK;MAC3E,IAAI,CAAC7C,uBAAuB,CAAC8C,GAAG,CAACF,EAAE,EAAED,UAAU,CAACH,MAAM,IAAI,IAAI,CAACxC,uBAAuB,CAAC+C,GAAG,CAACH,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC;MACrG,6BAAsD5F,eAAe,CAACmF,QAAQ,CAACQ,UAAU,CAAC;QAAlF3B,UAAU,0BAAVA,UAAU;QAAEoB,KAAK,0BAALA,KAAK;QAAEC,aAAa,0BAAbA,aAAa;QAAEC,OAAO,0BAAPA,OAAO;MACjD,IAAMC,WAAW,GAAG,IAAI7F,QAAQ,CAACU,WAAW,CAACuF,UAAU,CAACH,MAAM,EAAEJ,KAAK,EAAEC,aAAa,CAAC;MACrF,IAAMW,eAAe,GAAG,IAAItG,QAAQ,CAAC6E,eAAe,CAACgB,WAAW,EAAEK,EAAE,EAAEC,OAAO,CAAC;MAC9E,IAAMnC,OAAO,GAAGjE,OAAO,CAACsF,IAAI,CAACiB,eAAe,EAAEhC,UAAU,CAAC;MACzD,OAAO,IAAI,CACNc,aAAa,CAACpB,OAAO,CAAC,CACtBgC,iBAAiB,CAACJ,OAAO,CAAC;IACnC;EAAC;IAAA;IAAA,OAES,2BAAkBA,OAA0B;MAClD,IAAIzB,MAAuB;MAC3B,IAAIoC,IAAY,EAAEC,OAAe;MACjC,KAAK,IAAIC,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAGd,OAAO,CAACE,MAAM,EAAE,EAAEW,CAAC,GAAGC,CAAC,GAAG;QAC3C,IAAI,CAACvC,MAAM,GAAGyB,OAAO,CAACa,CAAC,CAAC,KAAK,CAACF,IAAI,GAAGpC,MAAM,CAACG,UAAU,IAAI,CAAC,EAAE;UACzD,IAAI,CAACQ,MAAM,CAACX,MAAM,CAAC;UACnB,IAAI,CAACqC,OAAO,GAAG,CAAED,IAAI,GAAG,CAAC,GAAI,CAAC,CAAC,IAAIA,IAAI,IAAI,CAAC,EAAE;YAC1C,IAAI,CAACtB,aAAa,CAACuB,OAAO,CAAC;;;;MAIvC,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OAES,4BAAmBhB,KAAqB;MAAA,4CACjBA,KAAK,CAACmB,YAAY;QAAA;MAAA;QAA/C,uDAAiD;UAAA;YAAvCT,EAAE;YAAED,UAAU;UACpB,IAAIW,MAAM,GAAG,IAAI,CAACtD,uBAAuB,CAAC+C,GAAG,CAACH,EAAE,CAAC,IAAI,CAAC;UACtD,IAAIU,MAAM,KAAK,CAAC,IAAI,CAACX,UAAU,GAAGA,UAAU,CAACY,KAAK,CAACD,MAAM,CAAC,EAAEd,MAAM,GAAG,CAAC,EAAE;YACpE,IAAM/B,MAAM,GAAG,QAAQ,IAAIkC,UAAU,GAAIA,UAAkB,CAAClC,MAAM,GAAG,CAACkC,UAAU,CAAC;YAAC,4CAC9DlC,MAAM;cAAA;YAAA;cAA1B,uDAA4B;gBAAA,IAAjBmB,KAAK;gBACZ,IAAI,CAAC4B,qBAAqB,CAAC5B,KAAK,EAAEgB,EAAE,EAAEU,MAAM,GAAG,CAAC,CAAC;gBACjDA,MAAM,IAAI1B,KAAK,CAACY,MAAM;;YACzB;cAAA;YAAA;cAAA;YAAA;;;MAER;QAAA;MAAA;QAAA;MAAA;MACD,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OAnPM,qBAAmB1E,OAAmE;MACzF,MAAM,IAAIuC,KAAK,qDAAmD;IACtE;IACA;EAAA;IAAA;IAAA,OACO;IACH;IACAoD,gBAA6E;IAC7E;IACAC,gBAAyD;MAEzD,MAAM,IAAIrD,KAAK,oDAAkD;IACrE;EAAC;EAAA;AAAA,EAf+E/C,eAA2B,EA4DnGuB,MAAM,CAACC,aAAa;AA8LhC;AACA,WAAa6E,uBAAqE;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OAK9E;IACO,kBAA6DpF,KAAU,EAAET,OAAwC;MACpH,IAAM8F,MAAM,GAAG,IAAID,uBAAuB,CAAI7F,OAAO,CAAC;MACtD,IAAIP,SAAS,CAAMgB,KAAK,CAAC,EAAE;QACvB,OAAOA,KAAK,CAACC,IAAI,CAAC,UAACC,CAAC;UAAA,OAAKmF,MAAM,CAAClF,QAAQ,CAACD,CAAC,CAAC;QAAA,EAAC;OAC/C,MAAM,IAAIjB,eAAe,CAAiBe,KAAK,CAAC,EAAE;QAC/C,OAAOI,aAAa,CAACiF,MAAM,EAAErF,KAAK,CAAC;;MAEvC,OAAOG,SAAQ,CAACkF,MAAM,EAAErF,KAAK,CAAC;IAClC;EAAC;EAAA;AAAA,EAdqFV,iBAAoB;AAiB9G;AACA,WAAagG,qBAAmE;EAAA;EAAA;EAgB5E;IAAA;IAAA;IACI;IACA,OAAK3F,YAAY,GAAG,IAAI;IAAC;EAC7B;EAdA;EAAA;IAAA;IAAA;IAgBA;IACU,sBAAaqB,MAAiB;MACpC,OAAO,IAAI,CAACuE,WAAW,EAAE,CAACnC,aAAa,CAAC,CAAC,CAAC;IAC9C;EAAC;IAAA;IAAA,OAES,sBAAapC,MAAiB;MACpC,IAAMsB,MAAM,GAAGjE,MAAM,CAACkE,MAAM,CAAC,IAAIlE,MAAM,CACnC2C,MAAM,EAAEzC,eAAe,CAACiH,EAAE,EAC1B,IAAI,CAAChE,kBAAkB,EAAE,IAAI,CAACD,iBAAiB,CAClD,CAAC;MACF,OAAO,wFACWP,MAAM,EAAE;MAAA,CACrBiC,MAAM,CAACX,MAAM,CAAC,CAAC;MAAA,CACfW,MAAM,CAACC,UAAU,CAACC,EAAE,CAACb,MAAM,CAACG,UAAU,CAAC,CAAC,CAAC;MAAA,CACzC8C,WAAW,EAAE,CAAC,CAAC;IACxB;EAAC;IAAA;IAAA,OA9BM,kBAA6DvF,KAAU;MAC1E,IAAMqF,MAAM,GAAG,IAAIC,qBAAqB,EAAK;MAC7C,IAAItG,SAAS,CAAMgB,KAAK,CAAC,EAAE;QACvB,OAAOA,KAAK,CAACC,IAAI,CAAC,UAACC,CAAC;UAAA,OAAKmF,MAAM,CAAClF,QAAQ,CAACD,CAAC,CAAC;QAAA,EAAC;OAC/C,MAAM,IAAIjB,eAAe,CAAiBe,KAAK,CAAC,EAAE;QAC/C,OAAOI,aAAa,CAACiF,MAAM,EAAErF,KAAK,CAAC;;MAEvC,OAAOG,SAAQ,CAACkF,MAAM,EAAErF,KAAK,CAAC;IAClC;EAAC;EAAA;AAAA,EAdmFV,iBAAoB;AAuC5G;AACA,WAAamG,qBAAmE;EAAA;EAAA;EAe5E;IAAA;IAAA;IACI;IACA,OAAK9F,YAAY,GAAG,IAAI;IACxB,OAAK+F,cAAc,GAAG,EAAE;IACxB,OAAKC,aAAa,GAAG,EAAE;IAAC;EAC5B;EAbA;EAAA;IAAA;IAAA,OAeU,yBAAa;MAAK,OAAO,IAAI;IAAE;IACzC;EAAA;IAAA;IAAA,OACU,sBAAa3E,MAAiB;MAAI,OAAO,IAAI;IAAE;EAAC;IAAA;IAAA,OAChD,sBAAaA,MAAiB;MACpC,OAAO,IAAI,CAACiC,MAAM,4BACd2C,IAAI,CAACC,SAAS,CAAC;QAAEC,MAAM,EAAE9E,MAAM,CAAC8E,MAAM,CAACC,GAAG,CAACC,WAAW;MAAC,CAAE,EAAE,IAAI,EAAE,CAAC,CACtE,EAAG;IACP;EAAC;IAAA;IAAA,OACS,4BAAmBrC,KAAqB;MAC9C,IAAIA,KAAK,CAACmB,YAAY,CAACJ,IAAI,GAAG,CAAC,EAAE;QAC7B,IAAI,CAACiB,aAAa,CAAC7C,IAAI,CAACa,KAAK,CAAC;;MAElC,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OACS,+BAAsBS,UAAkB,EAAEC,EAAU,EAAiB;MAAA,IAAfC,OAAO,uEAAG,KAAK;MAC3E,IAAI,CAAC7C,uBAAuB,CAAC8C,GAAG,CAACF,EAAE,EAAED,UAAU,CAACH,MAAM,IAAI,IAAI,CAACxC,uBAAuB,CAAC+C,GAAG,CAACH,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC;MACrG,IAAI,CAACpB,MAAM,CAAC,IAAI,CAAC1B,iBAAiB,CAAC0C,MAAM,KAAK,CAAC,qBAAqB,CAAC;MACrE,IAAI,CAAChB,MAAM,WAAIgD,qBAAqB,CAAC7B,UAAU,EAAEC,EAAE,EAAEC,OAAO,CAAC,EAAG;MAChE,IAAI,CAAC/C,iBAAiB,CAACuB,IAAI,CAAC,IAAI1E,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;MACnD,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OACS,2BAAkBuF,KAAqB;MAC7C,IAAI,CAACO,kBAAkB,CAACP,KAAK,CAAC;MAC9B,IAAI,CAAC+B,cAAc,CAAC5C,IAAI,CAACa,KAAK,CAAC;MAC/B,OAAO,IAAI;IACf;EAAC;IAAA;IAAA,OACM,iBAAK;MAER,IAAI,IAAI,CAACgC,aAAa,CAAC1B,MAAM,GAAG,CAAC,EAAE;QAC/B,IAAI,CAAChB,MAAM,8BAA4B;QAAC,4CACpB,IAAI,CAAC0C,aAAa;UAAA;QAAA;UAAtC,uDAAwC;YAAA,IAA7BhC,KAAK;YACZ,8FAAyBA,KAAK;;QACjC;UAAA;QAAA;UAAA;QAAA;QACD,IAAI,CAACV,MAAM,SAAS;;MAGxB,IAAI,IAAI,CAACyC,cAAc,CAACzB,MAAM,GAAG,CAAC,EAAE;QAChC,KAAK,IAAIW,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAG,IAAI,CAACa,cAAc,CAACzB,MAAM,EAAE,EAAEW,CAAC,GAAGC,CAAC,GAAG;UACvD,IAAI,CAAC5B,MAAM,CAAC2B,CAAC,KAAK,CAAC,0CAAwC,CAAC;UAC5D,IAAI,CAAC3B,MAAM,WAAIiD,iBAAiB,CAAC,IAAI,CAACR,cAAc,CAACd,CAAC,CAAC,CAAC,EAAG;UAC3D,IAAI,CAACpD,kBAAkB,CAACsB,IAAI,CAAC,IAAI1E,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;;QAExD,IAAI,CAAC6E,MAAM,SAAS;;MAGxB,IAAI,IAAI,CAACnC,OAAO,EAAE;QACd,IAAI,CAACmC,MAAM,OAAO;;MAGtB,IAAI,CAAC0C,aAAa,GAAG,EAAE;MACvB,IAAI,CAACD,cAAc,GAAG,EAAE;MAExB;IACJ;EAAC;IAAA;IAAA,OAnEM,kBAA6F1F,KAAU;MAC1G,OAAO,IAAIyF,qBAAqB,EAAK,CAACtF,QAAQ,CAACH,KAAY,CAAC;IAChE;EAAC;EAAA;AAAA,EAVmFV,iBAAoB;AA8E5G;AACA,SAASa,SAAQ,CAA8CkF,MAA4B,EAAErF,KAA0C;EACnI,IAAIkC,MAAM,GAAGlC,KAAiC;EAC9C,IAAIA,KAAK,YAAYnC,KAAK,EAAE;IACxBqE,MAAM,GAAGlC,KAAK,CAACkC,MAAM;IACrBmD,MAAM,CAAC3E,KAAK,CAACqB,SAAS,EAAE/B,KAAK,CAACgB,MAAM,CAAC;;EACxC,4CACmBkB,MAAM;IAAA;EAAA;IAA1B,uDAA4B;MAAA,IAAjByB,KAAK;MACZ0B,MAAM,CAAC/B,KAAK,CAACK,KAAK,CAAC;;EACtB;IAAA;EAAA;IAAA;EAAA;EACD,OAAO0B,MAAM,CAACrD,MAAM,EAAE;AAC1B;AAEA;AAAA,SACe5B,aAAa;EAAA;AAAA;AAO5B;AAAA;EAAA,4EAPA,iBAA0EiF,MAA4B,EAAEc,OAAsC;IAAA;IAAA;MAAA;QAAA;UAAA;YAAA;YAAA;YAAA;YAAA,2BAChHA,OAAO;UAAA;YAAA;YAAA;UAAA;YAAA;cAAA;cAAA;YAAA;YAAhBxC,KAAK;YAClB0B,MAAM,CAAC/B,KAAK,CAACK,KAAK,CAAC;UAAC;YAAA;YAAA;YAAA;UAAA;YAAA;YAAA;UAAA;YAAA;YAAA;YAAA;YAAA;UAAA;YAAA;YAAA;YAAA;cAAA;cAAA;YAAA;YAAA;YAAA;UAAA;YAAA;YAAA;cAAA;cAAA;YAAA;YAAA;UAAA;YAAA;UAAA;YAAA;UAAA;YAAA,iCAEjB0B,MAAM,CAACrD,MAAM,EAAE;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CACzB;EAAA;AAAA;AAGD,SAASgE,WAAW,OAAgC;EAAA,IAA7BI,IAAI,QAAJA,IAAI;IAAEnF,IAAI,QAAJA,IAAI;IAAEoF,QAAQ,QAARA,QAAQ;EACvC,IAAMC,SAAS,GAAG,IAAI5H,iBAAiB,EAAE;EACzC,OAAO;IACH,MAAM,EAAE0H,IAAI;IAAE,UAAU,EAAEC,QAAQ;IAClC,MAAM,EAAEC,SAAS,CAACC,KAAK,CAACtF,IAAI,CAAC;IAC7B,UAAU,EAAE,CAACA,IAAI,CAACuF,QAAQ,IAAI,EAAE,EAAET,GAAG,CAACC,WAAW,CAAC;IAClD,YAAY,EAAE,CAAChI,QAAQ,CAACyI,YAAY,CAACxF,IAAI,CAAC,GAAGc,SAAS,GAAG;MACrD,IAAI,EAAEd,IAAI,CAACoD,EAAE;MACb,WAAW,EAAEpD,IAAI,CAACyF,SAAS;MAC3B,WAAW,EAAEJ,SAAS,CAACC,KAAK,CAACtF,IAAI,CAAC0F,OAAO;;GAEhD;AACL;AAEA;AACA,SAASV,qBAAqB,CAAC7B,UAAkB,EAAEC,EAAU,EAAiB;EAAA,IAAfC,OAAO,uEAAG,KAAK;EAC1E,IAAMsC,KAAK,GAAG,IAAI3I,KAAK,WAAIoG,EAAE,GAAID,UAAU,CAACnD,IAAI,EAAEmD,UAAU,CAACyC,SAAS,GAAG,CAAC,CAAC;EAC3E,IAAMC,OAAO,GAAGnI,mBAAmB,CAACiF,QAAQ,CAAC,IAAI7F,MAAM,CAAC6I,KAAK,EAAE,CAACxC,UAAU,CAAC,CAAC,CAAC;EAC7E,OAAOwB,IAAI,CAACC,SAAS,CAAC;IAClB,IAAI,EAAExB,EAAE;IACR,SAAS,EAAEC,OAAO;IAClB,MAAM,EAAE;MACJ,OAAO,EAAEF,UAAU,CAACH,MAAM;MAC1B,SAAS,EAAE6C;;GAElB,EAAE,IAAI,EAAE,CAAC,CAAC;AACf;AAEA;AACA,SAASZ,iBAAiB,CAACa,OAAoB;EAC3C,OAAOnB,IAAI,CAACC,SAAS,CAAC;IAClB,OAAO,EAAEkB,OAAO,CAAC9C,MAAM;IACvB,SAAS,EAAEtF,mBAAmB,CAACiF,QAAQ,CAACmD,OAAO;GAClD,EAAE,IAAI,EAAE,CAAC,CAAC;AACf","names":["Table","MAGIC","Column","DataType","Field","Message","metadata","FileBlock","Footer","MessageHeader","MetadataVersion","AsyncByteQueue","VectorAssembler","JSONTypeAssembler","JSONVectorAssembler","toUint8Array","RecordBatch","_InternalEmptyPlaceholderRecordBatch","ReadableInterop","isPromise","isAsyncIterable","isWritableDOMStream","isWritableNodeStream","isIterable","isObject","RecordBatchWriter","options","Map","autoDestroy","writeLegacyIpcFormat","_autoDestroy","_writeLegacyIpcFormat","sync","_sink","toString","input","then","x","writeAll","writeAllAsync","closed","Symbol","asyncIterator","toDOMStream","toNodeStream","reset","close","reason","abort","_schema","sink","schema","type","pipeTo","objectMode","pipe","_started","_writeFooter","_dictionaryBlocks","_recordBatchBlocks","_dictionaryDeltaOffsets","compareTo","_position","_writeSchema","payload","Error","undefined","finish","_writeRecordBatch","chunks","message","alignment","a","buffer","encode","flatbufferSize","byteLength","prefixSize","alignedSize","nPaddingBytes","headerType","push","bodyLength","DictionaryBatch","_write","Int32Array","of","_writePadding","chunk","write","_writeMessage","from","nBytes","Uint8Array","batch","assemble","nodes","bufferRegions","buffers","recordBatch","length","_writeDictionaries","_writeBodyBuffers","dictionary","id","isDelta","set","get","dictionaryBatch","size","padding","i","n","dictionaries","offset","slice","_writeDictionaryBatch","writableStrategy","readableStrategy","RecordBatchStreamWriter","writer","RecordBatchFileWriter","_writeMagic","V4","RecordBatchJSONWriter","_recordBatches","_dictionaries","JSON","stringify","fields","map","fieldToJSON","dictionaryBatchToJSON","recordBatchToJSON","batches","name","nullable","assembler","visit","children","isDictionary","isOrdered","indices","field","nullCount","columns","records"],"sources":["ipc/writer.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Vector } from '../vector';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Schema, Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { WritableSink, AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { ArrayBufferViewInput, toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { Writable, ReadableInterop, ReadableDOMStreamOptions } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\n\nexport interface RecordBatchStreamWriterOptions {\n    /**\n     *\n     */\n    autoDestroy?: boolean;\n    /**\n     * A flag indicating whether the RecordBatchWriter should construct pre-0.15.0\n     * encapsulated IPC Messages, which reserves  4 bytes for the Message metadata\n     * length instead of 8.\n     * @see https://issues.apache.org/jira/browse/ARROW-6313\n     */\n    writeLegacyIpcFormat?: boolean;\n}\n\nexport class RecordBatchWriter<T extends { [key: string]: DataType } = any> extends ReadableInterop<Uint8Array> implements Writable<RecordBatch<T>> {\n\n    /** @nocollapse */\n    // @ts-ignore\n    public static throughNode(options?: import('stream').DuplexOptions & { autoDestroy: boolean }): import('stream').Duplex {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    public static throughDOM<T extends { [key: string]: DataType }>(\n        // @ts-ignore\n        writableStrategy?: QueuingStrategy<RecordBatch<T>> & { autoDestroy: boolean },\n        // @ts-ignore\n        readableStrategy?: { highWaterMark?: number, size?: any }\n    ): { writable: WritableStream<Table<T> | RecordBatch<T>>, readable: ReadableStream<Uint8Array> } {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n\n    constructor(options?: RecordBatchStreamWriterOptions) {\n        super();\n        isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n\n    protected _position = 0;\n    protected _started = false;\n    protected _autoDestroy: boolean;\n    protected _writeLegacyIpcFormat: boolean;\n    // @ts-ignore\n    protected _sink = new AsyncByteQueue();\n    protected _schema: Schema | null = null;\n    protected _dictionaryBlocks: FileBlock[] = [];\n    protected _recordBatchBlocks: FileBlock[] = [];\n    protected _dictionaryDeltaOffsets = new Map<number, number>();\n\n    public toString(sync: true): string;\n    public toString(sync?: false): Promise<string>;\n    public toString(sync: any = false) {\n        return this._sink.toString(sync) as Promise<string> | string;\n    }\n    public toUint8Array(sync: true): Uint8Array;\n    public toUint8Array(sync?: false): Promise<Uint8Array>;\n    public toUint8Array(sync: any = false) {\n        return this._sink.toUint8Array(sync) as Promise<Uint8Array> | Uint8Array;\n    }\n\n    public writeAll(input: Table<T> | Iterable<RecordBatch<T>>): this;\n    public writeAll(input: AsyncIterable<RecordBatch<T>>): Promise<this>;\n    public writeAll(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<any> | Table<T> | Iterable<RecordBatch<T>> | AsyncIterable<RecordBatch<T>>) {\n        if (isPromise<any>(input)) {\n            return input.then((x) => this.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, <any> input);\n    }\n\n    public get closed() { return this._sink.closed; }\n    public [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    public toDOMStream(options?: ReadableDOMStreamOptions) { return this._sink.toDOMStream(options); }\n    public toNodeStream(options?: import('stream').ReadableOptions) { return this._sink.toNodeStream(options); }\n\n    public close() {\n        return this.reset()._sink.close();\n    }\n    public abort(reason?: any) {\n        return this.reset()._sink.abort(reason);\n    }\n    public finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    public reset(sink: WritableSink<ArrayBufferViewInput> = this._sink, schema: Schema<T> | null = null) {\n\n        if ((sink === this._sink) || (sink instanceof AsyncByteQueue)) {\n            this._sink = sink as AsyncByteQueue;\n        } else {\n            this._sink = new AsyncByteQueue();\n            if (sink && isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            } else if (sink && isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n\n        if (!schema || !(schema.compareTo(this._schema))) {\n            if (schema === null) {\n                this._position = 0;\n                this._schema = null;\n            } else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n\n        return this;\n    }\n\n    public write(payload?: Table<T> | RecordBatch<T> | Iterable<RecordBatch<T>> | null) {\n\n        let schema: Schema<T> | null = null;\n\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        } else if (payload === null || payload === undefined) {\n            return this.finish() && undefined;\n        } else if (payload instanceof Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n\n        if (schema && !schema.compareTo(this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n\n        if (payload instanceof RecordBatch) {\n            if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        } else if (payload instanceof Table) {\n            this.writeAll(payload.chunks);\n        } else if (isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n\n    protected _writeMessage<T extends MessageHeader>(message: Message<T>, alignment = 8) {\n\n        const a = alignment - 1;\n        const buffer = Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n        if (message.headerType === MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        } else if (message.headerType === MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) { this._write(buffer); }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n\n    protected _write(chunk: ArrayBufferViewInput) {\n        if (this._started) {\n            const buffer = toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMessage(Message.from(schema));\n    }\n\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n\n    protected _writeMagic() {\n        return this._write(MAGIC);\n    }\n\n    protected _writePadding(nBytes: number) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n        const message = Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(dictionary);\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeBodyBuffers(buffers: ArrayBufferView[]) {\n        let buffer: ArrayBufferView;\n        let size: number, padding: number;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n                const chunks = 'chunks' in dictionary ? (dictionary as any).chunks : [dictionary];\n                for (const chunk of chunks) {\n                    this._writeDictionaryBatch(chunk, id, offset > 0);\n                    offset += chunk.length;\n                }\n            }\n        }\n        return this;\n    }\n}\n\n/** @ignore */\nexport class RecordBatchStreamWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): RecordBatchStreamWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any, options?: RecordBatchStreamWriterOptions) {\n        const writer = new RecordBatchStreamWriter<T>(options);\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\n\n/** @ignore */\nexport class RecordBatchFileWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchFileWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any) {\n        const writer = new RecordBatchFileWriter<T>();\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n\n    // @ts-ignore\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMagic()._writePadding(2);\n    }\n\n    protected _writeFooter(schema: Schema<T>) {\n        const buffer = Footer.encode(new Footer(\n            schema, MetadataVersion.V4,\n            this._recordBatchBlocks, this._dictionaryBlocks\n        ));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\n\n/** @ignore */\nexport class RecordBatchJSONWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchJSONWriter<T>;\n    // @ts-ignore\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: any) {\n        return new RecordBatchJSONWriter<T>().writeAll(input as any);\n    }\n\n    private _recordBatches: RecordBatch[];\n    private _dictionaries: RecordBatch[];\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n\n    protected _writeMessage() { return this; }\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) { return this; }\n    protected _writeSchema(schema: Schema<T>) {\n        return this._write(`{\\n  \"schema\": ${\n            JSON.stringify({ fields: schema.fields.map(fieldToJSON) }, null, 2)\n        }`);\n    }\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n        return this;\n    }\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    public close() {\n\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n\n        this._dictionaries = [];\n        this._recordBatches = [];\n\n        return super.close();\n    }\n}\n\n/** @ignore */\nfunction writeAll<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, input: Table<T> | Iterable<RecordBatch<T>>) {\n    let chunks = input as Iterable<RecordBatch<T>>;\n    if (input instanceof Table) {\n        chunks = input.chunks;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nasync function writeAllAsync<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, batches: AsyncIterable<RecordBatch<T>>) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }: Field): object {\n    const assembler = new JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map(fieldToJSON),\n        'dictionary': !DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary: Vector, id: number, isDelta = false) {\n    const field = new Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n    const columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n\n/** @ignore */\nfunction recordBatchToJSON(records: RecordBatch) {\n    return JSON.stringify({\n        'count': records.length,\n        'columns': JSONVectorAssembler.assemble(records)\n    }, null, 2);\n}\n"]},"metadata":{},"sourceType":"module"}